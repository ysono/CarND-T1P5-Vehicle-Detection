{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.stats\n",
    "import skimage.feature\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.svm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_paths(car_paths, noncar_paths):\n",
    "    \"\"\"Depends on global function `GET_RAW_FEATURES_FROM_IMAGE`,\n",
    "    which takes one arg of path string and returns one 1-dimensinoal np array of features.\"\"\"\n",
    "    \n",
    "    car_raw_features, noncar_raw_features = [\n",
    "        [GET_RAW_FEATURES_FROM_IMAGE(path) for path in paths]\n",
    "        for paths in [car_paths, noncar_paths]\n",
    "    ]\n",
    "    \n",
    "    X = np.vstack((car_raw_features, noncar_raw_features)).astype(np.float64)\n",
    "    print('pre-split features shape is', X.shape)\n",
    "\n",
    "    y = np.hstack((np.ones(len(car_raw_features)), np.zeros(len(noncar_raw_features))))\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# def get_features_small():\n",
    "#     car_paths = glob.glob('working_dir/vehicles_smallset/**/*')\n",
    "#     noncar_paths = glob.glob('working_dir/non-vehicles_smallset/**/*')\n",
    "#     return get_features_from_paths(car_paths, noncar_paths)\n",
    "\n",
    "def get_features_large():\n",
    "    t0 = time.time()\n",
    "    \n",
    "    car_paths = glob.glob('working_dir/vehicles/**/*')\n",
    "    noncar_paths = glob.glob('working_dir/non-vehicles/**/*')\n",
    "    features = get_features_from_paths(car_paths, noncar_paths)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(round(t1 - t0, 2), 'Seconds to collect features')\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A legacy version of training and validating pipeline.\n",
    "# This 1) searches for an optimal SVC using the small dataset, and\n",
    "# 2) uses LinearSVC with default parameters on the large dataset, and\n",
    "# 3) compares their accuracies.\n",
    "# In the final pipeline, searching is omitted, because it has consistently been much more\n",
    "# expensive than and has yielded worse models than the latter strategy.\n",
    "'''\n",
    "def train_and_validate___legacy():\n",
    "    \"\"\"Before running, set global function `GET_RAW_FEATURES_FROM_IMAGE`.\"\"\"\n",
    "    \n",
    "    def train_and_validate_small():\n",
    "        (X_train, X_test, y_train, y_test), X_scaler = get_classifier_features_small()\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        grid_search_params = {\n",
    "            'C': scipy.stats.expon(scale=100),\n",
    "            'gamma': scipy.stats.expon(scale=.1),\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'class_weight':['balanced', None]}\n",
    "        clf = sklearn.model_selection.RandomizedSearchCV(sklearn.svm.SVC(), grid_search_params)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        t1 = time.time()\n",
    "        \n",
    "        print(round(t1 - t0, 2), 'Seconds to optimize SVC')\n",
    "        print('score of optimized classifier on small dataset', clf.score(X_test, y_test))\n",
    "        print('optimized classifier params', clf.best_params_)\n",
    "\n",
    "        return X_scaler, clf\n",
    "    \n",
    "    def train_and_validate_large(optimized_clf):\n",
    "        (X_train, X_test, y_train, y_test), X_scaler = get_classifier_features_large()\n",
    "    \n",
    "        # it's prob not ok to use a different X_scaler than the classifier was trained for, like in this line here...\n",
    "        print('score of optimized classifier on large dataset', optimized_clf.score(X_test, y_test))\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        simple_clf = sklearn.svm.LinearSVC()\n",
    "        simple_clf.fit(X_train, y_train)\n",
    "\n",
    "        t1 = time.time()\n",
    "        \n",
    "        print(round(t1 - t0, 2), 'Seconds to train default LinearSVC')\n",
    "        print('score of default LinearSVC on large dataset', simple_clf.score(X_test, y_test))\n",
    "\n",
    "        return X_scaler, simple_clf\n",
    "    \n",
    "    X_scaler_small, optimized_clf = train_and_validate_small()\n",
    "    X_scaler_large, simple_clf = train_and_validate_large(optimized_clf)\n",
    "    return X_scaler_small, X_scaler_large, optimized_clf, simple_clf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate():\n",
    "    \"\"\"Before running, set global function `GET_RAW_FEATURES_FROM_IMAGE`.\"\"\"\n",
    "    \n",
    "    X, y = get_features_large()\n",
    "    \n",
    "    X_scaler = sklearn.preprocessing.StandardScaler().fit(X)\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        scaled_X, y, test_size=0.2)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    clf = sklearn.svm.LinearSVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(round(t1 - t0, 2), 'Seconds to train default LinearSVC')\n",
    "    print('score of default LinearSVC on large dataset', clf.score(X_test, y_test))\n",
    "    \n",
    "    return X_scaler, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hog features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog_helper(img_single_ch):\n",
    "    pixels_per_cell = 8\n",
    "    cells_per_block = 2\n",
    "    orientations = 9\n",
    "    \n",
    "    return skimage.feature.hog(\n",
    "        img_single_ch,\n",
    "        orientations=orientations,\n",
    "        pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "        cells_per_block=(cells_per_block, cells_per_block),\n",
    "        transform_sqrt=True,\n",
    "        visualise=False,\n",
    "        feature_vector=False,\n",
    "        block_norm='L2-Hys')\n",
    "\n",
    "def create_hog_features_getter(img_bgr_to_hog_features):\n",
    "    def getter(path):\n",
    "        img_bgr = cv2.imread(path)\n",
    "        assert img_bgr.shape[:2] == (64, 64)\n",
    "\n",
    "        hog = img_bgr_to_hog_features(img_bgr)\n",
    "        assert hog.shape[0] == hog.shape[1]\n",
    "\n",
    "        return hog.flatten()\n",
    "    \n",
    "    return getter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 1764)\n",
      "85.7 Seconds to collect features\n",
      "18.0 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.918355855856\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_yuv(img_bgr):\n",
    "    img_yuv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YUV)\n",
    "    img_ych = img_yuv[:,:,0]\n",
    "    return hog_helper(img_ych)\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_hog_features_getter(get_hog_features_yuv)\n",
    "\n",
    "YUV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 3528)\n",
      "77.66 Seconds to collect features\n",
      "20.66 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.956362612613\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_hsv(img_bgr):\n",
    "    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    img_sch = img_hsv[:,:,1]\n",
    "    img_vch = img_hsv[:,:,2]\n",
    "    hog_sch = hog_helper(img_sch)\n",
    "    hog_vch = hog_helper(img_vch)\n",
    "    return np.stack((hog_sch, hog_vch), axis=-1)\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_hog_features_getter(get_hog_features_hsv)\n",
    "\n",
    "HSV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 3528)\n",
      "76.83 Seconds to collect features\n",
      "19.76 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.95411036036\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_hls(img_bgr):\n",
    "    img_hls = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HLS)\n",
    "    img_lch = img_hls[:,:,1]\n",
    "    img_sch = img_hls[:,:,2]\n",
    "    hog_lch = hog_helper(img_lch)\n",
    "    hog_sch = hog_helper(img_sch)\n",
    "    return np.stack((hog_lch, hog_sch), axis=-1)\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_hog_features_getter(get_hog_features_hls)\n",
    "\n",
    "HLS_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### luv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 1764)\n",
      "67.86 Seconds to collect features\n",
      "18.99 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.917511261261\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_luv(img_bgr):\n",
    "    img_luv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LUV)\n",
    "    img_lch = img_luv[:,:,0]\n",
    "    return hog_helper(img_lch)\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_hog_features_getter(get_hog_features_luv)\n",
    "\n",
    "LUV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ycrcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 1764)\n",
      "40.87 Seconds to collect features\n",
      "18.35 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.918355855856\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_ycrcb(img_bgr):\n",
    "    img_ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    img_ych = img_ycrcb[:,:,0]\n",
    "    return hog_helper(img_ych)\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_hog_features_getter(get_hog_features_ycrcb)\n",
    "\n",
    "YCRCB_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('working_dir/hog_training_result.p', 'wb') as f:\n",
    "    training_result = {\n",
    "        'YUV_RESULTS': YUV_RESULTS,\n",
    "        'HSV_RESULTS': HSV_RESULTS,\n",
    "        'HLS_RESULTS': HLS_RESULTS,\n",
    "        'LUV_RESULTS': LUV_RESULTS,\n",
    "        'YCRCB_RESULTS': YCRCB_RESULTS\n",
    "    }\n",
    "    pickle.dump(training_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hog and color features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_color_features_getter(img_bgr_to_color_features, shrunk_dim=24, img_bgr_to_hog_features=get_hog_features_hsv):\n",
    "    def getter(path):\n",
    "        img_bgr = cv2.imread(path)\n",
    "        \n",
    "        # for hog, hsv is the winner.\n",
    "        hog = img_bgr_to_hog_features(img_bgr).flatten()\n",
    "        assert hog.shape == (7 * 7 * 2 * 2 * 9 * 2,)\n",
    "        \n",
    "        img_bgr_shrunk = cv2.resize(img_bgr, (shrunk_dim, shrunk_dim))\n",
    "        clr, num_chs = img_bgr_to_color_features(img_bgr_shrunk)\n",
    "        assert clr.shape == ((shrunk_dim * shrunk_dim + 32) * num_chs,)\n",
    "\n",
    "        return np.concatenate((hog, clr))\n",
    "    \n",
    "    return getter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4136)\n",
      "80.8 Seconds to collect features\n",
      "16.28 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.970439189189\n"
     ]
    }
   ],
   "source": [
    "def get_color_features_rgb(img_bgr_shrunk):\n",
    "    rch = img_bgr_shrunk[:,:,2]\n",
    "    \n",
    "    spatial = rch.flatten()\n",
    "    \n",
    "    hist = np.histogram(rch, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((spatial, hist[0])), 1\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rgb)\n",
    "\n",
    "CLR_RGB_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4136)\n",
      "124.75 Seconds to collect features\n",
      "18.26 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.965371621622\n"
     ]
    }
   ],
   "source": [
    "def get_color_features_hsv(img_bgr_shrunk):\n",
    "    img_hsv = cv2.cvtColor(img_bgr_shrunk, cv2.COLOR_BGR2HSV)\n",
    "    sch = img_hsv[:,:,1]\n",
    "    \n",
    "    spatial = sch.flatten()\n",
    "    \n",
    "    hist = np.histogram(sch, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((spatial, hist[0])), 1\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_hsv)\n",
    "\n",
    "CLR_HSV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4136)\n",
      "127.37 Seconds to collect features\n",
      "16.97 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.963119369369\n"
     ]
    }
   ],
   "source": [
    "def get_color_features_yuv(img_bgr_shrunk):\n",
    "    img_yuv = cv2.cvtColor(img_bgr_shrunk, cv2.COLOR_BGR2YUV)\n",
    "    ych = img_yuv[:,:,0]\n",
    "    \n",
    "    spatial = ych.flatten()\n",
    "    \n",
    "    hist = np.histogram(ych, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((spatial, hist[0])), 1\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_yuv)\n",
    "\n",
    "CLR_YUV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r and s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4744)\n",
      "128.5 Seconds to collect features\n",
      "17.87 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.973817567568\n"
     ]
    }
   ],
   "source": [
    "def get_color_features_rs(img_bgr_shrunk):\n",
    "    rch = img_bgr_shrunk[:,:,2]\n",
    "    \n",
    "    img_hsv = cv2.cvtColor(img_bgr_shrunk, cv2.COLOR_BGR2HSV)\n",
    "    sch = img_hsv[:,:,1]\n",
    "    \n",
    "    rch_spatial = rch.flatten()\n",
    "    sch_spatial = sch.flatten()\n",
    "    rch_hist = np.histogram(rch, bins=32, range=(0, 256))\n",
    "    sch_hist = np.histogram(sch, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((rch_spatial, sch_spatial, rch_hist[0], sch_hist[0])), 2\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rs)\n",
    "\n",
    "CLR_RS_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shrink differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4584)\n",
      "128.23 Seconds to collect features\n",
      "18.64 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.968186936937\n"
     ]
    }
   ],
   "source": [
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rgb, shrunk_dim=32)\n",
    "\n",
    "CLR_R_SHRUNK32_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 3816)\n",
      "91.27 Seconds to collect features\n",
      "14.63 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.967905405405\n"
     ]
    }
   ],
   "source": [
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rgb, shrunk_dim=16)\n",
    "\n",
    "CLR_R_SHRUNK16_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 5640)\n",
      "82.88 Seconds to collect features\n",
      "22.87 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.974943693694\n"
     ]
    }
   ],
   "source": [
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rs, shrunk_dim=32)\n",
    "\n",
    "CLR_RS_SHRUNK32_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4104)\n",
      "77.17 Seconds to collect features\n",
      "14.47 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.977477477477\n"
     ]
    }
   ],
   "source": [
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rs, shrunk_dim=16)\n",
    "\n",
    "CLR_RS_SHRUNK16_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try hls for hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4104)\n",
      "79.2 Seconds to collect features\n",
      "14.02 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.96509009009\n"
     ]
    }
   ],
   "source": [
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rs, shrunk_dim=16, img_bgr_to_hog_features=get_hog_features_hls)\n",
    "\n",
    "HOG_LS_CLR_RS_SHRUNK16_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try hls for color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4104)\n",
      "128.09 Seconds to collect features\n",
      "15.97 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.971283783784\n"
     ]
    }
   ],
   "source": [
    "def get_color_features_ls(img_bgr_shrunk):\n",
    "    img_hls = cv2.cvtColor(img_bgr_shrunk, cv2.COLOR_BGR2HLS)\n",
    "    lch = img_hls[:,:,1]\n",
    "    sch = img_hls[:,:,2]\n",
    "    \n",
    "    lch_spatial = lch.flatten()\n",
    "    sch_spatial = sch.flatten()\n",
    "    lch_hist = np.histogram(lch, bins=32, range=(0, 256))\n",
    "    sch_hist = np.histogram(sch, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((lch_spatial, sch_spatial, lch_hist[0], sch_hist[0])), 2\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_ls, shrunk_dim=16, img_bgr_to_hog_features=get_hog_features_hls)\n",
    "\n",
    "HOG_LS_CLR_LS_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-split features shape is (17760, 4392)\n",
      "130.0 Seconds to collect features\n",
      "14.1 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.97240990991\n"
     ]
    }
   ],
   "source": [
    "def get_color_features_rls(img_bgr_shrunk):\n",
    "    rch = img_bgr_shrunk[:,:,2]\n",
    "    \n",
    "    img_hls = cv2.cvtColor(img_bgr_shrunk, cv2.COLOR_BGR2HLS)\n",
    "    lch = img_hls[:,:,1]\n",
    "    sch = img_hls[:,:,2]\n",
    "    \n",
    "    rch_spatial = rch.flatten()\n",
    "    lch_spatial = lch.flatten()\n",
    "    sch_spatial = sch.flatten()\n",
    "    rch_hist = np.histogram(rch, bins=32, range=(0, 256))\n",
    "    lch_hist = np.histogram(lch, bins=32, range=(0, 256))\n",
    "    sch_hist = np.histogram(sch, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((rch_spatial, lch_spatial, sch_spatial, rch_hist[0], lch_hist[0], sch_hist[0])), 3\n",
    "\n",
    "GET_RAW_FEATURES_FROM_IMAGE = create_color_features_getter(get_color_features_rls, shrunk_dim=16, img_bgr_to_hog_features=get_hog_features_hls)\n",
    "\n",
    "HOG_LS_CLR_RLS_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('working_dir/overall_training_result.p', 'wb') as f:\n",
    "    overall_training_result = {\n",
    "        'CLR_RGB_RESULTS': CLR_RGB_RESULTS,\n",
    "        'CLR_HSV_RESULTS': CLR_HSV_RESULTS,\n",
    "        'CLR_YUV_RESULTS': CLR_YUV_RESULTS,\n",
    "        'CLR_RS_RESULTS': CLR_RS_RESULTS,\n",
    "        'CLR_R_SHRUNK32_RESULTS': CLR_R_SHRUNK32_RESULTS,\n",
    "        'CLR_R_SHRUNK16_RESULTS': CLR_R_SHRUNK16_RESULTS,\n",
    "        'CLR_RS_SHRUNK32_RESULTS': CLR_RS_SHRUNK32_RESULTS,\n",
    "        'CLR_RS_SHRUNK16_RESULTS': CLR_RS_SHRUNK16_RESULTS,\n",
    "        'HOG_LS_CLR_RS_SHRUNK16_RESULTS': HOG_LS_CLR_RS_SHRUNK16_RESULTS,\n",
    "        'HOG_LS_CLR_LS_RESULTS': HOG_LS_CLR_LS_RESULTS,\n",
    "        'HOG_LS_CLR_RLS_RESULTS': HOG_LS_CLR_RLS_RESULTS\n",
    "    }\n",
    "    pickle.dump(overall_training_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
