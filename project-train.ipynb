{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.stats\n",
    "import skimage.feature\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import sklearn.svm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hog features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hog_helper(img_single_ch):\n",
    "    pixels_per_cell = 8\n",
    "    cells_per_block = 2\n",
    "    orientations = 9\n",
    "    \n",
    "    return skimage.feature.hog(\n",
    "        img_single_ch,\n",
    "        orientations=orientations,\n",
    "        pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "        cells_per_block=(cells_per_block, cells_per_block),\n",
    "        transform_sqrt=True,\n",
    "        visualise=False,\n",
    "        feature_vector=False,\n",
    "        block_norm='L2-Hys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features_from_test_image(path):\n",
    "    \"\"\"Depends on global function `GET_HOG_FEATURES_FROM_IMAGE`.\"\"\"\n",
    "    \n",
    "    img_bgr = cv2.imread(path)\n",
    "    assert img_bgr.shape[:2] == (64, 64)\n",
    "    \n",
    "    hog = GET_HOG_FEATURES_FROM_IMAGE(img_bgr)\n",
    "    assert hog.shape[0] == hog.shape[1]\n",
    "    \n",
    "    return hog.flatten()\n",
    "\n",
    "def get_classifier_features(car_hog_features, noncar_hog_features):\n",
    "    X = np.vstack((car_hog_features, noncar_hog_features)).astype(np.float64)\n",
    "    print('classifier features shape is', X.shape)\n",
    "\n",
    "    X_scaler = sklearn.preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "\n",
    "    y = np.hstack((np.ones(len(car_hog_features)), np.zeros(len(noncar_hog_features))))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        scaled_X, y, test_size=0.2)\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test), X_scaler\n",
    "\n",
    "def get_classifier_features_from_paths(car_paths, noncar_paths):\n",
    "    car_hog_features, noncar_hog_features = [\n",
    "        [get_hog_features_from_test_image(path) for path in paths]\n",
    "        for paths in [car_paths, noncar_paths]\n",
    "    ]\n",
    "    print('training set size is', [len(features) for features in [car_hog_features, noncar_hog_features]])\n",
    "    \n",
    "    return get_classifier_features(car_hog_features, noncar_hog_features)\n",
    "\n",
    "def get_classifier_features_small():\n",
    "    car_paths = glob.glob('working_dir/vehicles_smallset/**/*')\n",
    "    noncar_paths = glob.glob('working_dir/non-vehicles_smallset/**/*')\n",
    "    return get_classifier_features_from_paths(car_paths, noncar_paths)\n",
    "\n",
    "def get_classifier_features_large():\n",
    "    car_paths = glob.glob('working_dir/vehicles/**/*')\n",
    "    noncar_paths = glob.glob('working_dir/non-vehicles/**/*')\n",
    "    return get_classifier_features_from_paths(car_paths, noncar_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_validate():\n",
    "    \"\"\"Before running, set global function `GET_HOG_FEATURES_FROM_IMAGE`.\"\"\"\n",
    "    \n",
    "    def train_and_validate_small():\n",
    "        (X_train, X_test, y_train, y_test), X_scaler = get_classifier_features_small()\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        grid_search_params = {\n",
    "            'C': scipy.stats.expon(scale=100),\n",
    "            'gamma': scipy.stats.expon(scale=.1),\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'class_weight':['balanced', None]}\n",
    "        clf = sklearn.model_selection.RandomizedSearchCV(sklearn.svm.SVC(), grid_search_params)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        t1 = time.time()\n",
    "        \n",
    "        print(round(t1 - t0, 2), 'Seconds to optimize SVC')\n",
    "        print('score of optimized classifier on small dataset', clf.score(X_test, y_test))\n",
    "        print('optimized classifier params', clf.best_params_)\n",
    "\n",
    "        return X_scaler, clf\n",
    "    \n",
    "    def train_and_validate_large(optimized_clf):\n",
    "        (X_train, X_test, y_train, y_test), X_scaler = get_classifier_features_large()\n",
    "    \n",
    "        print('score of optimized classifier on large dataset', optimized_clf.score(X_test, y_test))\n",
    "\n",
    "        t0 = time.time()\n",
    "\n",
    "        simple_clf = sklearn.svm.LinearSVC()\n",
    "        simple_clf.fit(X_train, y_train)\n",
    "\n",
    "        t1 = time.time()\n",
    "        \n",
    "        print(round(t1 - t0, 2), 'Seconds to train default LinearSVC')\n",
    "        print('score of default LinearSVC on large dataset', simple_clf.score(X_test, y_test))\n",
    "\n",
    "        return X_scaler, simple_clf\n",
    "    \n",
    "    \n",
    "    X_scaler_small, optimized_clf = train_and_validate_small()\n",
    "    X_scaler_large, simple_clf = train_and_validate_large(optimized_clf)\n",
    "    return X_scaler_small, X_scaler_large, optimized_clf, simple_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size is [1196, 1125]\n",
      "classifier features shape is (2321, 1764)\n",
      "138.6 Seconds to optimize SVC\n",
      "score of optimized classifier on small dataset 0.94623655914\n",
      "optimized classifier params {'class_weight': None, 'C': 15.51560389085947, 'gamma': 0.060393851905433817, 'kernel': 'linear'}\n",
      "training set size is [8792, 8968]\n",
      "classifier features shape is (17760, 1764)\n",
      "score of optimized classifier on large dataset 0.84009009009\n",
      "22.71 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.918074324324\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_yuv(img_bgr):\n",
    "    img_yuv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YUV)\n",
    "    img_ych = img_yuv[:,:,0]\n",
    "    return hog_helper(img_ych)\n",
    "\n",
    "GET_HOG_FEATURES_FROM_IMAGE = get_hog_features_yuv\n",
    "\n",
    "YUV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size is [1196, 1125]\n",
      "classifier features shape is (2321, 3528)\n",
      "341.43 Seconds to optimize SVC\n",
      "score of optimized classifier on small dataset 0.967741935484\n",
      "optimized classifier params {'class_weight': None, 'C': 203.54919322663201, 'gamma': 0.002980498106739218, 'kernel': 'rbf'}\n",
      "training set size is [8792, 8968]\n",
      "classifier features shape is (17760, 3528)\n",
      "score of optimized classifier on large dataset 0.907376126126\n",
      "23.18 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.957488738739\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_hsv(img_bgr):\n",
    "    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    img_sch = img_hsv[:,:,1]\n",
    "    img_vch = img_hsv[:,:,2]\n",
    "    hog_sch = hog_helper(img_sch)\n",
    "    hog_vch = hog_helper(img_vch)\n",
    "    return np.stack((hog_sch, hog_vch), axis=-1)\n",
    "\n",
    "GET_HOG_FEATURES_FROM_IMAGE = get_hog_features_hsv\n",
    "\n",
    "HSV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size is [1196, 1125]\n",
      "classifier features shape is (2321, 3528)\n",
      "243.39 Seconds to optimize SVC\n",
      "score of optimized classifier on small dataset 0.967741935484\n",
      "optimized classifier params {'class_weight': 'balanced', 'C': 77.099607798986028, 'gamma': 0.023107860854446646, 'kernel': 'linear'}\n",
      "training set size is [8792, 8968]\n",
      "classifier features shape is (17760, 3528)\n",
      "score of optimized classifier on large dataset 0.862331081081\n",
      "23.59 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.952702702703\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_hls(img_bgr):\n",
    "    img_hls = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HLS)\n",
    "    img_lch = img_hls[:,:,1]\n",
    "    img_sch = img_hls[:,:,2]\n",
    "    hog_lch = hog_helper(img_lch)\n",
    "    hog_sch = hog_helper(img_sch)\n",
    "    return np.stack((hog_lch, hog_sch), axis=-1)\n",
    "\n",
    "GET_HOG_FEATURES_FROM_IMAGE = get_hog_features_hls\n",
    "\n",
    "HLS_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### luv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size is [1196, 1125]\n",
      "classifier features shape is (2321, 1764)\n",
      "124.67 Seconds to optimize SVC\n",
      "score of optimized classifier on small dataset 0.954838709677\n",
      "optimized classifier params {'class_weight': 'balanced', 'C': 111.27604465991836, 'gamma': 0.0099291947018337184, 'kernel': 'rbf'}\n",
      "training set size is [8792, 8968]\n",
      "classifier features shape is (17760, 1764)\n",
      "score of optimized classifier on large dataset 0.889076576577\n",
      "22.32 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.928490990991\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_luv(img_bgr):\n",
    "    img_luv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LUV)\n",
    "    img_lch = img_luv[:,:,0]\n",
    "    return hog_helper(img_lch)\n",
    "\n",
    "GET_HOG_FEATURES_FROM_IMAGE = get_hog_features_luv\n",
    "\n",
    "LUV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ycrcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size is [1196, 1125]\n",
      "classifier features shape is (2321, 1764)\n",
      "138.84 Seconds to optimize SVC\n",
      "score of optimized classifier on small dataset 0.969892473118\n",
      "optimized classifier params {'class_weight': 'balanced', 'C': 13.143214309351748, 'gamma': 0.0056035539553426451, 'kernel': 'rbf'}\n",
      "training set size is [8792, 8968]\n",
      "classifier features shape is (17760, 1764)\n",
      "score of optimized classifier on large dataset 0.887668918919\n",
      "23.2 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.920045045045\n"
     ]
    }
   ],
   "source": [
    "def get_hog_features_ycrcb(img_bgr):\n",
    "    img_ycrcb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "    img_ych = img_ycrcb[:,:,0]\n",
    "    return hog_helper(img_ych)\n",
    "\n",
    "GET_HOG_FEATURES_FROM_IMAGE = get_hog_features_ycrcb\n",
    "\n",
    "YCRCB_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('working_dir/hog_training_result.p', 'wb') as f:\n",
    "    training_result = {\n",
    "        'yuv_results': YUV_RESULTS,\n",
    "        'hsv_results': HSV_RESULTS,\n",
    "        'hls_results': HLS_RESULTS,\n",
    "        'luv_results': LUV_RESULTS,\n",
    "        'ycrcb_results': YCRCB_RESULTS\n",
    "    }\n",
    "    pickle.dump(training_result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hog and color features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Warning, hiding the function above!\n",
    "### Also, the name is now a misnomer, since we're adding histogram and spatial binning.\n",
    "def get_hog_features_from_test_image(path):\n",
    "    \"\"\"Depends on global function `GET_COLOR_FEATURES_FROM_IMAGE`.\"\"\"\n",
    "    \n",
    "    img_bgr = cv2.imread(path)\n",
    "    \n",
    "    # for hog, hsv is the winner.\n",
    "    hog = get_hog_features_hsv(img_bgr).flatten()\n",
    "    assert hog.shape == (7 * 7 * 2 * 2 * 9 * 2,)\n",
    "    \n",
    "    clr = GET_COLOR_FEATURES_FROM_IMAGE(img_bgr)\n",
    "    assert clr.shape == (24 * 24 + 32,)\n",
    "    \n",
    "    return np.concatenate((hog, clr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size is [1196, 1125]\n",
      "classifier features shape is (2321, 4136)\n",
      "312.38 Seconds to optimize SVC\n",
      "score of optimized classifier on small dataset 0.989247311828\n",
      "optimized classifier params {'class_weight': None, 'C': 218.15986146051839, 'gamma': 0.00038997838423473563, 'kernel': 'rbf'}\n",
      "training set size is [8792, 8968]\n",
      "classifier features shape is (17760, 4136)\n",
      "score of optimized classifier on large dataset 0.910472972973\n",
      "23.83 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.969031531532\n"
     ]
    }
   ],
   "source": [
    "def color_features_hsv(img_bgr_64):\n",
    "    img_bgr_24 = cv2.resize(img_bgr_64, (24, 24))\n",
    "    img_hsv_24 = cv2.cvtColor(img_bgr_24, cv2.COLOR_BGR2HSV)\n",
    "    sch = img_hsv_24[:,:,1]\n",
    "    \n",
    "    spatial = sch.flatten()\n",
    "    \n",
    "    hist = np.histogram(sch, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((spatial, hist[0]))\n",
    "\n",
    "GET_COLOR_FEATURES_FROM_IMAGE = color_features_hsv\n",
    "\n",
    "CLR_HSV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yuv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size is [1196, 1125]\n",
      "classifier features shape is (2321, 4136)\n",
      "307.19 Seconds to optimize SVC\n",
      "score of optimized classifier on small dataset 0.963440860215\n",
      "optimized classifier params {'class_weight': 'balanced', 'C': 246.71716974322243, 'gamma': 0.088727278500685292, 'kernel': 'linear'}\n",
      "training set size is [8792, 8968]\n",
      "classifier features shape is (17760, 4136)\n",
      "score of optimized classifier on large dataset 0.910191441441\n",
      "20.45 Seconds to train default LinearSVC\n",
      "score of default LinearSVC on large dataset 0.965934684685\n"
     ]
    }
   ],
   "source": [
    "def color_features_yuv(img_bgr_64):\n",
    "    img_bgr_24 = cv2.resize(img_bgr_64, (24, 24))\n",
    "    img_yuv_24 = cv2.cvtColor(img_bgr_24, cv2.COLOR_BGR2YUV)\n",
    "    ych = img_yuv_24[:,:,0]\n",
    "    \n",
    "    spatial = ych.flatten()\n",
    "    \n",
    "    hist = np.histogram(ych, bins=32, range=(0, 256))\n",
    "    \n",
    "    return np.concatenate((spatial, hist[0]))\n",
    "\n",
    "GET_COLOR_FEATURES_FROM_IMAGE = color_features_yuv\n",
    "\n",
    "CLR_YUV_RESULTS = train_and_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('working_dir/overall_training_result.p', 'wb') as f:\n",
    "    overall_training_result = {\n",
    "        'clr_hsv_results': CLR_HSV_RESULTS,\n",
    "        'clr_yuv_results': CLR_YUV_RESULTS\n",
    "    }\n",
    "    pickle.dump(overall_training_result, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carnd-term1",
   "language": "python",
   "name": "carnd-term1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
